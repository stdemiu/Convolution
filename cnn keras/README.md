# Модель CNN через Keras

## Подключение библиотек
```python
from tensorflow.keras.preprocessing import image
```

Keras image: Для загрузки и преобразования изображений.

## Создание CNN модели
```python

inputs = layers.Input(shape=(224, 224, 3))
x = layers.Conv2D(32, (3, 3), activation='relu')(inputs)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Conv2D(64, (3, 3), activation='relu')(x)
x = layers.MaxPooling2D((2, 2))(x)
x = layers.Conv2D(64, (3, 3), activation='relu')(x)
x = layers.Flatten()(x)
x = layers.Dense(64, activation='relu')(x)
outputs = layers.Dense(10, activation='softmax')(x)

model = tf.keras.models.Model(inputs=inputs, outputs=outputs)
```

Эта часть создаёт простую архитектуру CNN:

1. inputs = layers.Input(shape=(224, 224, 3)): Входной слой принимает изображение размером 224×224 с тремя каналами (RGB).
2. layers.Conv2D: Три свёрточных слоя:
    - Первый слой: Применяет 32 фильтра 3×3, активация ReLU. Функция активации ReLU (Rectified Linear Unit), которая заменяет все отрицательные значения на ноль. Этот слой "сканирует" изображение с помощью фильтров, создавая карты признаков, которые подчеркивают особенности, например, края, текстуры и формы. Каждый фильтр будет учиться находить определенные признаки (например, горизонтальные или вертикальные грани).
  
      
    - Второй слой: Применяет 64 фильтра 3×3, активация ReLU. После первого макспулинга изображение стало меньше, и теперь сеть способна фокусироваться на более высокоуровневых признаках, таких как углы и текстуры.
      
    - Третий слой: Применяет 64 фильтра 3×3, активация ReLU. На этом этапе сеть может выделять уже более сложные и абстрактные признаки, комбинируя низкоуровневые признаки, такие как края, в более высокоуровневые, такие как текстуры и формы.

      
3. layers.MaxPooling2D((2, 2)): После первых двух свёрточных слоёв применяется подвыборка (макспулинг), уменьшая размер признаков вдвое. (2, 2): Размер окна, которое скользит по изображениям признаков, выбирая максимальное значение в каждом окне. Сохраняет наиболее значимые признаки, что делает CNN устойчивой к небольшим смещениям и деформациям в изображении.
4. layers.Flatten(): Преобразует данные в одномерный массив для полносвязного слоя. Полносвязные слои (следующёие за Flatten) работают с одномерными массивами, поэтому карты признаков нужно "распрямить". Это позволяет создать один длинный вектор с информацией о всех признаках, выделенных свёрточными слоями.

5. layers.Dense(64, activation='relu'): Полносвязный слой из 64 нейронов. Он объединяет признаки, выделенные свёрточными слоями, и помогает сети сделать окончательное предсказание. Полносвязные слои помогают объединять информацию и находить нелинейные зависимости между признаками.

6. layers.Dense(10, activation='softmax'): Выходной слой для 10 классов (например, для задачи классификации с 10 метками). Это финальный слой, где сеть принимает решение о классе изображения. Функция активации softmax преобразует выходные значения в вероятности, которые суммируются до 1. Softmax выбирает класс с наибольшей вероятностью.

   
## Компиляция модели
```python
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
```

- optimizer='adam': Оптимизатор Adam для эффективного обучения.
- loss='sparse_categorical_crossentropy': Функция потерь, подходящая для задач многоклассовой классификации.
- metrics=['accuracy']: Отслеживает точность.

Adam (Adaptive Moment Estimation) — это популярный алгоритм оптимизации, который сочетает в себе преимущества двух других методов: AdaGrad и RMSProp.
- Адаптивное обучение: Adam динамически изменяет скорость обучения для каждого параметра, что помогает эффективно справляться как с быстрыми, так и с медленными изменениями градиента.
- Сочетание среднего и дисперсии градиентов: Adam отслеживает как среднее значение градиента, так и его дисперсию. Это помогает избежать застревания в локальных минимумах и ускоряет сходимость.

Adam является одним из самых популярных оптимизаторов для обучения нейронных сетей благодаря своей эффективности и устойчивости. Он работает лучше и быстрее в большинстве случаев по сравнению с такими оптимизаторами, как SGD (Stochastic Gradient Descent), особенно на больших и сложных моделях.


sparse_categorical_crossentropy — это функция потерь, которая используется для задач многоклассовой классификации, когда метки классов представлены целыми числами.
- Многоклассовая классификация: Эта функция подходит, когда модель должна классифицировать объекты на более чем два класса (например, если классов 10, как в этом случае).
- Sparse (разреженные) метки: Эта версия функции потерь используется, когда метки классов заданы в виде целых чисел (например, 0, 1, 2 и т.д.), а не в виде "one-hot" векторов (например, [1, 0, 0], [0, 1, 0], ...). Это экономит память и упрощает обучение.
  
 
## Прогон изображения через модель
```python
model.predict(img_array)
```
Выполняет прямой проход (feedforward) изображения через модель и возвращает предсказания, основываясь на текущих значениях весов слоев модели. Позднее мы будем использовать модель для извлечения промежуточных активаций (выходов свёрточных слоёв) — это возможно только после того, как слои модели полностью инициализированы. Без этого шага могут возникнуть ошибки, так как TensorFlow/Keras может не понять, какие данные инициализировать для промежуточных слоёв.


## Извлечение активаций свёрточных слоёв
```python
layer_outputs = [layer.output for layer in model.layers[:6]]
activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)
```

- layer_outputs: Извлекает выходные данные первых шести слоёв, включая все свёрточные и пулинг слои.
- activation_model: Создаёт новую модель, которая возвращает активации указанных слоёв, что удобно для визуализации признаков.


## Применение модели активации к изображению
```python
activations = activation_model.predict(img_array)
activations: Содержит активации (или карты признаков) для каждого указанного слоя.
```

## Визуализация карт признаков
Первый свёрточный слой
```python
first_layer_activation = activations[0]
plt.matshow(first_layer_activation[0, :, :, 0], cmap='viridis')
plt.title('Первый свёрточный слой - Карта признаков')
plt.show()
```

1. first_layer_activation = activations[0]: Извлекает активации (карты признаков) первого свёрточного слоя.
    - activations — это список выходных данных (активаций) от первых слоёв модели, полученных через activation_model.predict(img_array).
    - activations[0] — это карты признаков первого свёрточного слоя.

2. plt.matshow(first_layer_activation[0, :, :, 0], cmap='viridis'):
    - first_layer_activation[0, :, :, 0] извлекает первую карту признаков первого свёрточного слоя (первая по каналу).
    - cmap='viridis' задаёт цветовую схему, которая помогает лучше различать уровни активаций.
      
На этом уровне свёрточная сеть выделяет простые признаки, такие как края и текстуры. Это первый уровень абстракции, который позволяет сети уловить основные формы объекта.


Второй свёрточный слой
```python
second_layer_activation = activations[2]
plt.matshow(second_layer_activation[0, :, :, 0], cmap='viridis')
plt.title('Второй свёрточный слой - Карта признаков')
plt.show()
```

1. second_layer_activation = activations[2]: Извлекает активации второго свёрточного слоя.
    - activations[2] — это карта признаков, полученная после второго свёрточного слоя.
2. plt.matshow(second_layer_activation[0, :, :, 0], cmap='viridis'):
    - second_layer_activation[0, :, :, 0] берёт первую карту признаков второго свёрточного слоя.
    - Использование цветовой схемы viridis делает активации более наглядными.
      
На втором уровне сеть начинает выделять более сложные признаки, такие как углы, более крупные грани и текстуры. Здесь сеть видит уже не только отдельные линии, но и комбинации линий, что создаёт основу для распознавания контуров объектов.

Третий свёрточный слой
```python
third_layer_activation = activations[4]
plt.matshow(third_layer_activation[0, :, :, 0], cmap='viridis')
plt.title('Третий свёрточный слой - Карта признаков')
plt.show()
```
1. third_layer_activation = activations[4]: Извлекает активации третьего свёрточного слоя.
    - activations[4] — это карта признаков после третьего свёрточного слоя.

2. plt.matshow(third_layer_activation[0, :, :, 0], cmap='viridis'):
    - third_layer_activation[0, :, :, 0] берёт первую карту признаков третьего свёрточного слоя.
    - viridis используется для контрастного отображения уровня активаций.
